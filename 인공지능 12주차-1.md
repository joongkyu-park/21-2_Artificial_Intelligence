# 인공지능 12주차-1

CNN 계속

5)
컴퓨터가 X와 O의 사진을 구분하기
Comper vision(컴퓨터가 사람과같이 무언갈 보는것)을 이용한다.  Computer vision은 복잡하다.

7)
여러 X와 O 모양을 컴퓨터가 인지하는 것이 쉽지가 않다

이렇게 classify가 가능하다면, prediction 하는 것도 비슷하다.
여러 X, O의 데이터를 학습해서 분류가 가능하면 어떤 사진을 보고 이게 X, O인지 분별하는게 같다는 뜻

8)
이 2개를 같다고 판단하는게 쉽지 않다

11)
과거의 전통적인 방법으로 했을 때는 왼쪽과 오른쪽을 어떻게 비교했나
-> exact match를 했다. 첫번째 픽셀끼리 비교,…
그런데 그게 안되니까 확률로 비교

12)
그러나 딥러닝에선 블락단위로 비교했다.
블락끼리 같은지 안같은지 비교.
-> 같아질 확률이 높아진다.
-> CNN의 아이디어의 기초

블락단위의 매칭은 직관적으로 생각하면,
사람의 눈으로 다른 사람으로 인식할때
픽셀 : 사람의 피부색을 1픽셀 1픽셀을 비교하여 기억
	-> 메모리가 너무 많아서 사람이 기억하지 못함..
CNN : 눈이라는 큰 블락, 코라는 큰 블락의 측면으로 바라봐서 특징점으로 이해
	-> feature(특징점)의 정보가 누적되어서 사람은 사람을 보고 사람이라고 생각을 한다. 이 점을 컴퓨터로 구현하려는 것

13)
여기서는 3개의 패턴을 가지고 생각할 수 있다

14)
이러한 패턴들이 빈번하게 나타나면 X로 구분할 수 있다고 아이디어를 생각할 수 있겠다.

15,16)
Filtering : ..?

저 가생이의 덧댄 부분을 pacth라고 한다
![인공지능 12주차-1](images/인공지능%2012주차-1.png)

17)
계산방법
여기서는 9개의 픽셀을 1블락으로 생각

이미지에서 블락으로 잡은 부분과, 패턴과 비교하여 픽셀이 같으면 1, 아니면 -1 로 해서 9개의 매칭값을 다더하고 9로 나눈 값을, 가운데 픽셀자리값으로 넣는다.

19)
여기서 1.00 값이 되는건 패턴과 정확하기 일치하는 구간들.

픽셀 단위로 비교했다면 너무 좁은 단위로 비교했는데
여기선 3x3 블락단위로 비교하여 조금더 큰 단위로 비교 할 수 있게된것.

20)
이렇게 Filtering된 이미지가 중첩되게 된다.
이런걸 Convolution layer(중첩 레이어)라고 한다

21)
Pooling : 이미지 스택을 줄이는 것

22)
풀링 예시

여기서는 2x2에서 맥시멈값을 취해서 1x1로 수축시킨다.
매트릭스는 작아지지만, 특징점 입장에서는 특징점을 하나 골라서 summary를 해버리는 격이된다. 2x2 중에 가장 강한 특징점을 하나 선택하는 것이다. 그것이 pooling

24~25)
Normalization
마이너스값을 0로 만들어버린다.

이전에 시그모이드 함수가 필요했던 이유 : 스텝적인 function이 아닌 비선형적인 완만한 모양으로 만들기 위해서
그거와 같은 이유처럼 시그모이드를 쓸 수도 있고 Rectified linear Units을 쓸 수 있는 것. 같은 이유로 사용되는 것이고 시그모이드의 또다른 형태라고 생각하면 된다.

27~28)
이런 식으로 레이어들이 쌓인다.
이 레이어들을 히든레이어라고 하고, 이 히든 레이어들이 많아서 딥러닝이라고 말하는 것

29)
무조건 X, 무조건 O로 분류하는게 아니라(100%가 될 수없음)
![인공지능 12주차-1-1](images/인공지능%2012주차-1-1.png)

다음과 같이 확률적으로 구분하게 된다.

false positive
인공지능은 positive라고 답했지만, 실제로는 false인 경우.
인공지능을 맹신하지 않고 이런 경우을 잘 해결해야겠다

그러나 자율주행같은 실시간적인 상황에서는 사용자가 권한을 가지고 결정할 수 없으므로 더 정확성을 높여야겠다..

30)
이 레이어들이 매우매우 깊기 때문에 딥러닝 인것.
매우 깊으니까 matrix computation이 엄청나게 많을 것이다.
판단을 하기전에 많은 양의 데이터를 학습하게 될 것이다.
-> 학습하는데 시간이 많이 소요될 것이다. 레이어가 깊으니까 행렬연산이 너무 많아서. 또 그래서 하드웨어를 엄청나게 잡아먹게 될것.

32)
Backpropagtion
right answer과 actual answer의 차이인 error을 통해 학습을 시킨다.

33)
그 error값을 minimize시키도록 학습하는게 목표.

34)

35)
머신러닝에서의 아키텍쳐
CNN, RNN, GANN … 등의 아키텍쳐들이 존재한다.

이 아키텍쳐를 새로 만드는건 미국에서 주로 하고,
우리나라같은 경우에는 아키텍쳐를 새로 만들지 않고 레이어를 조금 modify하고 그러면서 응용하고 논문을 내고 그러는 것.
아키텍쳐에 손을 댈 수 있는 사람은 많지 않다..

36)
이 CNN의 하나의 아키텍쳐이다.

38)
CNN 아키텍쳐를 사용하는 것들.
CNN 아키텍쳐를 조금씩 modify해서 인식률을 높이려고 한다.

39)
파라메터의 개수가 .. 매우 많다
각각의 특징들이 있다.

