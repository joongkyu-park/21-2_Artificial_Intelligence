# 인공지능 10주차-2

다시 교수님 수업.
Connectionist AI Ch2

9)부터시작
~13)
뇌의 뉴런은 스텝으로 0 1처럼 딱딱 on/off 되는게 아니라
logistic한 모양처럼 적용된다.
range를 갖음.

이렇게 뉴런들이 정보를 전달하고 역전파되고 그러는 neural net에서
가장 중요하고 기본적인게 행렬곱셈.

행렬곱셈은 expensive한 연산이다. 연산량, 계산량 많음

행렬곱셈은 컴퓨터 그래픽이나 비디오에서 처리할 때 주로 사용

14~16)
왜 행렬곱셈을 사용하는가

학습 : 행렬의 링크의 파라메터의 크기(가중치, weight)를 계속해서 조정해나가는게 것 -> ground truth data를 가능한한 많이 만족시키는 weight값을 구하는 것(최적화)
학습을 통해 output과 ground truth data와 오차를 줄이는것
error = target - actual

ground truth는 input과 output의 pair. 항상 사실인 것

17)
damage : 뉴런이 좀 손상되고 그래도 괜찮다. 우회하고 그러면됨..
imperfect sign : 인풋에 좀 노이즈가 들어가고 그래도 괜찮다
traditional computing -> 폰노이만 아키텍쳐

![인공지능 10주차-2](images/인공지능%2010주차-2.png)

25)
hidden layer가 많은 것이 deep neural net

27)
backward propagation
-> 전치행렬을 구해서 곱함.
![인공지능 10주차-2-1](images/인공지능%2010주차-2-1.png)

