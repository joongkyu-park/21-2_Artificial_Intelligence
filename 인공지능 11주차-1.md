# 인공지능 11주차-1

Matrix ppt

3)
행렬을 신경망을 구현하기위한 하나의 자료구조로 생각.

4~마지막
행렬 연산에 관한 설명. 신경망 곱하는게 행렬곱하는 거기때문에 참고.
->⭐️ 행렬곱하는거 시험에 나옴. 17)에 transpose 같은거도.

**# Artificial Intelligence**
**Lecture Note**
**
**
***학습방법*** 
ppt

3)
구체적으로 matrix multiplication에 대해
신경망에서 forward proapagation, backward propagation 다룬다

foward propagation 연산과정 한 번 쭉 훑어보자

*주의 : w1,3 은 1열의 3번째 원소.

행렬은 굉장히 비싼 연산.
히든 레이어가 많아질수록, 행렬의 크기가 클수록(100x100이라면..? 그리고 시그모이드 함수도 매번 곱해줘야하고..)

7)
머신러닝하는데 GPU가 필요한 이유가 뭐야?
일반적으로 영상에 프레임을 다룰때 1초에 40~50개의 장면들을 이어서 보여주는건데,
모든 vertex를 움직이고 새로운 좌표를 계산하는데, 이 계산이 행렬연산임.
따라서 머신러닝, 딥러닝의 기본인 행렬곱하기연산이라 GPU가 적합.
-> GPU는 행렬연산에 강해서 CPU보다 훨씬 빠르다.

10)
output 결과값 가지고 뭐하나.
학습을 한다는 것은 과거의 ground truth data의 (Input, Output)쌍이 수천만개 존재할 때, input을 넣었을때 행렬연산결과의 값(actual)과 ground truth data의 output의 결과(target)의 차이를 error라고함.

학습이란 이런 error가 작아지도록 가중치를 조정하는 작업이다.

최초 가중치값은 어떻게 정해지는 건가?
-> 그냥 임의의 랜덤값을 주고, 그냥 back propagation으로 가중치 계속 조정
물론 시작하는 가중치가 좋으면 좋겠지만 그걸 알아내기가 쉽지 않으니까 그냥 0~1사이의 랜덤값으로 진행한다고 보면 되겠다

11)
backprogation 과정 설명

17)
*주의 : back할 때는 W21는 2행 1열.
	-> transpose 관계

19)
gradient descent 자세히는 나중에

23)
이게 실제 input, output

어떤 인풋을 넣었더니 에러가 0이야, 다른 인풋을 넣었더니 에러가 좀 있어..
이거 어떻게 평가해야하나?
또 에러를 어떻게 측정해야하나? 그냥 빼기? 절대값? 차이의 제곱?

에러 하나하나를 개별적으로 평가하는게 아니라, 총체적으로 평가하는것
-> 이 평균을 back propagation 시키는것

25)
19)도 참고하면서
gradient descent(경사하강법)
에러가 최소가 되는, 베스트 값(최적)으로 가기 위해 계속 조정해 나가는데,
에러값을 y값으로 봤을때 기울기가 점점 완만해지는 쪽으로 가게된다.
최적을 만드는것.
뭐에 대해 최적?
이 에러함수에 대해서 최적인걸 찾아내는게 머신러닝.
-> 컴퓨터에서 최적이란 것은, 항상 특정한 “함수” 대비 최적이라는 뜻.
에러함수는 사람이 준다.(그러나 이 에러함수를 기계가 만들수도 있다.)

21)
이 함수가 항상 working하지는 않는다.
global 최적해는 따로 있는데 local 최적해에 빠져서 최적의 값을 찾아내지 못할 수 있다.
-> 국소최적해에 빠질 수 있다.

대부분의 현실적인 문제는 2차원이아니라 다차원이다(매개변수가 여러개가 되니까)

