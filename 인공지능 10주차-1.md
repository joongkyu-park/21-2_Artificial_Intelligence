# 인공지능 10주차-1

#  인공지능 10주차-1

조교 matrix multiplication 수업.

2)~

8)
질문 : activation(non linear)부분이 존재하는 이유를 다시 들어보고 싶습니다.

답변 : activation function이존재하는이유는 아지즈가 설명한것처럼 non-linear 유닛을 붙혀줌으로써 뉴럴네트워크를 충분히 복잡하게하여 선형문제가 아닌경우(비선형문제)에도 뉴럴네트워크가 해결할수있기 위함입니다.

질문: sigmoid를 적용시키는 이유를 다시 들어보고 싶습니다.

답변 : 기본적으로 sigmoid는 activation function이기 때문에 activation function을 쓰는 이유와같습니다. 실제로 activation function에는 여러가지 종류가있는데 그중에 sigmoid를 쓰는 이유는 gradient descent중 갑자기 기울기가 변하는 현상등이 발생하지 않고(이 현상은 뉴럴네트워크의 성능을 감소시킵니다) 연산에 조금 용이함이있습니다. 하지만 단점도 있기때문에 다른 activation function이 사용되기도 합니다. 본 강의에서는 커버하기에 너무 넓은 범위이기때문에 더욱 궁금한게있으면 참고할만한 자료를 보내드리겠습니다.

질문 : How to know “the error function” and “here is the minimum point”?

답변 …

